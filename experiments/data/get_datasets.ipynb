{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interim-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "if os.getcwd().split('/')[-1] == 'data':\n",
    "    os.chdir('..')\n",
    "\n",
    "from util import get_openml_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-report",
   "metadata": {},
   "source": [
    "# credit card default\n",
    "https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "affected-stream",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1yff8lGjjBOUB_-M4FJOolXgnBX_akfiZ\n",
      "To: /Users/keyan/bair/imodels/experiments/UCI_Credit_Card.zip\n",
      "100%|██████████████████████████████████████| 1.00M/1.00M [00:00<00:00, 2.97MB/s]\n",
      "Archive:  UCI_Credit_Card.zip\n",
      "  inflating: UCI_Credit_Card.csv     \n"
     ]
    }
   ],
   "source": [
    "!gdown 'https://drive.google.com/uc?id=1yff8lGjjBOUB_-M4FJOolXgnBX_akfiZ'\n",
    "!unzip UCI_Credit_Card.zip\n",
    "!rm UCI_Credit_Card.zip\n",
    "!mkdir data/credit_card\n",
    "!mv UCI_Credit_Card.csv data/credit_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "interesting-mechanics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"data/credit_card/UCI_Credit_Card.csv\")\n",
    "\n",
    "df_raw.columns = [col.lower() for col in df_raw.columns]\n",
    "orig_feature_count = len(df_raw.columns) - 2\n",
    "orig_feature_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "union-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['sex', 'education', 'marriage']\n",
    "df_enc = pd.get_dummies(df_raw, columns=categorical_features, prefix_sep=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "virtual-oliver",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_enc.drop(['id', 'default.payment.next.month'], axis=1), df_enc['default.payment.next.month']\n",
    "df_tgt_last = pd.concat((X, y), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "royal-gregory",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tgt_last.to_csv(\"data/credit_card/credit_card_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-benjamin",
   "metadata": {},
   "source": [
    "# recidivism\n",
    "https://github.com/propublica/compas-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "jewish-expert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'compas-analysis'...\n",
      "remote: Enumerating objects: 31, done.\u001b[K\n",
      "remote: Total 31 (delta 0), reused 0 (delta 0), pack-reused 31\u001b[K\n",
      "Unpacking objects: 100% (31/31), done.\n"
     ]
    }
   ],
   "source": [
    "!git -C data clone https://github.com/propublica/compas-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "secondary-simon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"data/compas-analysis/compas-scores-two-years.csv\")\n",
    "df_raw['c_jail_time'] = (pd.to_datetime(df_raw['c_jail_out']) - pd.to_datetime(df_raw['c_jail_in'])).dt.days\n",
    "cols_interest = ['id', 'age', 'c_charge_degree', 'race', 'age_cat', 'score_text', 'sex', \n",
    "                 'priors_count', 'days_b_screening_arrest', 'decile_score', 'is_recid', \n",
    "                 'c_jail_in', 'c_jail_out', 'c_jail_time', 'two_year_recid']\n",
    "df = df_raw[cols_interest]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-prior",
   "metadata": {},
   "source": [
    "### follow same filtering process as propublica analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "strong-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['is_recid'] != -1]\n",
    "df = df[df['c_charge_degree'] != 'O']\n",
    "df = df[df['score_text'] != 'N/A']\n",
    "df = df[df['days_b_screening_arrest'].abs() <= 30]\n",
    "df = df.drop(['c_jail_in', 'c_jail_out'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "exciting-carolina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_feature_count = len(df.columns) - 3\n",
    "orig_feature_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "mexican-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enc = pd.get_dummies(df, prefix_sep=':')\n",
    "df_enc.columns = df_enc.columns.str.replace(' ', '_')\n",
    "X, y = df_enc.drop(['id', 'two_year_recid', 'is_recid'], axis=1), df_enc['is_recid']\n",
    "\n",
    "df_tgt_last = pd.concat((X, y), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "right-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tgt_last.to_csv('data/compas-analysis/compas_two_year_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-boxing",
   "metadata": {},
   "source": [
    "# juvenile \n",
    "https://www.icpsr.umich.edu/web/NACJD/studies/3986"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "congressional-panel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1wEFXutadmevTt1PUpjaDv4XH9KkSMdbx\n",
      "To: /Users/keyan/bair/imodels/experiments/ICPSR_03986.zip\n",
      "2.42MB [00:00, 3.68MB/s]\n",
      "Archive:  ICPSR_03986.zip\n",
      "   creating: ICPSR_03986/\n",
      "  inflating: ICPSR_03986/.DS_Store   \n",
      "  inflating: ICPSR_03986/03986-manifest.txt  \n",
      "   creating: ICPSR_03986/DS0001/\n",
      "  inflating: ICPSR_03986/DS0001/03986-0001-User_guide.pdf  \n",
      "   creating: ICPSR_03986/DS0001/03986-0001-Codebook/\n",
      "  inflating: ICPSR_03986/DS0001/03986-0001-Codebook/Questionnaire.pdf  \n",
      "  inflating: ICPSR_03986/DS0001/03986-0001-Data.txt  \n",
      "  inflating: ICPSR_03986/03986-descriptioncitation.html  \n",
      "  inflating: ICPSR_03986/03986-related_literature.txt  \n",
      "  inflating: ICPSR_03986/TermsOfUse.html  \n",
      "  inflating: ICPSR_03986/DS0001/feature_info.csv  \n"
     ]
    }
   ],
   "source": [
    "!gdown 'https://drive.google.com/uc?id=1wEFXutadmevTt1PUpjaDv4XH9KkSMdbx'\n",
    "!unzip ICPSR_03986.zip\n",
    "!rm ICPSR_03986.zip\n",
    "!mv ICPSR_03986 data/ICPSR_03986"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-player",
   "metadata": {},
   "source": [
    "### create df from raw txt data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "enabling-composer",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_rows = open('data/ICPSR_03986/DS0001/03986-0001-Data.txt').read().split('\\n')\n",
    "\n",
    "# consolidated info from 03986-0001-Codebook/Questionnaire.pdf and 03986-0001-User_guide.pdf\n",
    "metadata = pd.read_csv('data/ICPSR_03986/DS0001/feature_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "golden-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [[] for _ in range(len(raw_rows) - 1)]\n",
    "\n",
    "for i in range(len(rows)):\n",
    "    for j, l in zip(metadata['start_ind'], metadata['length']):\n",
    "        rows[i].append(raw_rows[i][j:j+l])\n",
    "\n",
    "for i in range(len(rows)):\n",
    "    rows[i] = list(map(lambda x: x.strip(), rows[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "intended-decision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4023, 280)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(rows)\n",
    "df.columns = metadata['feature_name'].values\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-standing",
   "metadata": {},
   "source": [
    "### clean missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "blessed-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['missing_vals_set'] = metadata['missing_val'].astype(str) + ' ' + metadata['missing_val_2'].astype(str)\n",
    "metadata['missing_vals_set'] += ' ' + metadata['missing_val_3'].astype(str)\n",
    "metadata['missing_vals_set'] = (\n",
    "    metadata['missing_vals_set'].apply(lambda x: set([v[:-2] for v in x.split(' ') if v != 'nan']))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "tribal-translation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4023, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.loc[:, ~metadata['over_10_percent_missing'].values]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adverse-glucose",
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_col_missing_val_sets = metadata[~metadata['over_10_percent_missing']]['missing_vals_set']\n",
    "for i in range(df.shape[1]):\n",
    "    curr_feat_missing_values = rem_col_missing_val_sets.iloc[i]\n",
    "    df = df[~df.iloc[:, i].isin(curr_feat_missing_values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-affiliation",
   "metadata": {},
   "source": [
    "### separate outcome variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "attempted-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_variables = metadata['feature_name'][\n",
    "    metadata['delinquent_behavior'].astype(bool) & metadata['feature_name'].isin(df.columns)\n",
    "]\n",
    "drop_variables = list(outcome_variables) + ['id', 'any_deviance']\n",
    "X_cat, y = df.drop(drop_variables, axis=1), df['any_deviance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dimensional-serum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_feature_count = len(X_cat.columns)\n",
    "orig_feature_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-tissue",
   "metadata": {},
   "source": [
    "### encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "desirable-purchase",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = metadata['feature_name'][\n",
    "    metadata['categorical'].astype(bool) & metadata['feature_name'].isin(X_cat.columns)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "honest-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X_cat, columns=categorical_features, prefix_sep=':').astype('float32')\n",
    "y = y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "twelve-lottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.concat([X, y], axis=1)\n",
    "df_clean.to_csv('data/ICPSR_03986/DS0001/data_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-internet",
   "metadata": {},
   "source": [
    "# diabetes readmission\n",
    "https://archive.ics.uci.edu/ml/datasets/diabetes+130-us+hospitals+for+years+1999-2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "rental-calculation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import imodels\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "# m = imodels.BoostedRulesClassifier(n_estimators=10)\n",
    "# m.fit(X_train, y_train, feature_names=X_train.columns)\n",
    "\n",
    "# accuracy_score(y_test, m.predict(X_test))\n",
    "# m.rules_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "according-estate",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1rOoEbLjMYsyamKeq4WFwHNdSZXPcRQUH\n",
      "To: /Users/keyan/bair/imodels/experiments/readmission.zip\n",
      "4.48MB [00:01, 3.88MB/s]\n",
      "Archive:  readmission.zip\n",
      "   creating: readmission/\n",
      "  inflating: readmission/diabetic_data.csv  \n",
      "  inflating: readmission/description.pdf  \n"
     ]
    }
   ],
   "source": [
    "!gdown 'https://drive.google.com/uc?id=1rOoEbLjMYsyamKeq4WFwHNdSZXPcRQUH'\n",
    "!unzip readmission.zip\n",
    "!rm readmission.zip\n",
    "!mv readmission data/readmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "impossible-disorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/readmission/diabetic_data.csv')\n",
    "df = df.replace({'?': np.nan})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-halloween",
   "metadata": {},
   "source": [
    "### target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ranking-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['readmitted'] = df['readmitted'].replace({'NO': 0, '>30': 1, '<30': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-happiness",
   "metadata": {},
   "source": [
    "### race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "exact-presence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['race'] = df['race'].replace({np.nan: 'Other'})\n",
    "df = pd.get_dummies(df, columns=['race'], prefix_sep=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-transaction",
   "metadata": {},
   "source": [
    "### gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "incorrect-vampire",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['gender'] != 'Unknown/Invalid']\n",
    "df = pd.get_dummies(df, columns=['gender'], prefix_sep=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-premium",
   "metadata": {},
   "source": [
    "### age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "parallel-cheese",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = df['age'].replace({\"[70-80)\":\"70+\",\n",
    "                               \"[60-70)\":\"[50-70)\",\n",
    "                               \"[50-60)\":\"[50-70)\",\n",
    "                               \"[80-90)\":\"70+\",\n",
    "                               \"[40-50)\":\"[20-50)\",\n",
    "                               \"[30-40)\":\"[20-50)\",\n",
    "                               \"[90-100)\":\"70+\",\n",
    "                               \"[20-30)\":\"[20-50)\"})\n",
    "df = pd.get_dummies(df, columns=['age'], prefix_sep=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-lithuania",
   "metadata": {},
   "source": [
    "### admission type id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ruled-summer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['admission_type_id'] = df['admission_type_id'].replace({1.0:\"Emergency\",\n",
    "                                                           2.0:\"Emergency\",\n",
    "                                                           3.0:\"Elective\",\n",
    "                                                           4.0:\"New Born\",\n",
    "                                                           5.0:np.nan,\n",
    "                                                           6.0:np.nan,\n",
    "                                                           7.0:\"Trauma Center\",\n",
    "                                                           8.0:np.nan})\n",
    "df = pd.get_dummies(df, columns=['admission_type_id'], prefix_sep=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-pixel",
   "metadata": {},
   "source": [
    "### discharge disposition ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "representative-calvin",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['discharge_disposition_id'] = df['discharge_disposition_id'].replace(\n",
    "    {1:\"Discharged to Home\",\n",
    "     6:\"Discharged to Home\",\n",
    "     8:\"Discharged to Home\",\n",
    "     13:\"Discharged to Home\",\n",
    "     19:\"Discharged to Home\",\n",
    "     18:np.nan, 25:np.nan, 26:np.nan,\n",
    "     2:\"Other\", 3:\"Other\", 4:\"Other\",\n",
    "     5:\"Other\", 7:\"Other\", 9:\"Other\",\n",
    "     10:\"Other\", 11:\"Other\", 12:\"Other\",\n",
    "     14:\"Other\", 15:\"Other\", 16:\"Other\",\n",
    "     17:\"Other\", 20:\"Other\", 21:\"Other\",\n",
    "     22:\"Other\", 23:\"Other\", 24:\"Other\",\n",
    "     27:\"Other\", 28:\"Other\", 29:\"Other\", 30:\"Other\"}\n",
    ") \n",
    "df = pd.get_dummies(df, columns=['discharge_disposition_id'], prefix_sep=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-patent",
   "metadata": {},
   "source": [
    "### admission source ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "rotary-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['admission_source_id'] = df['admission_source_id'].replace(\n",
    "    {1:\"Referral\", 2:\"Referral\", 3:\"Referral\", 4:\"Transfer\",\n",
    "     5:\"Transfer\", 6:\"Transfer\", 7:\"Emergency\", 8:\"Other\",\n",
    "     9:\"Other\", 10:\"Transfer\", 11:\"Other\", 12:\"Other\",\n",
    "     13:\"Other\", 14:\"Other\", 15:np.nan, 17:np.nan, \n",
    "     18:\"Transfer\", 19:\"Other\", 20:np.nan, 21:np.nan,\n",
    "     22:\"Transfer\", 23:\"Other\", 24: \"Other\", 25:\"Transfer\",\n",
    "     26: \"Transfer\"}\n",
    ")\n",
    "df = pd.get_dummies(df, columns=['admission_source_id'], prefix_sep=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-planning",
   "metadata": {},
   "source": [
    "### medical specialty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "gorgeous-ebony",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['medical_specialty'] = df['medical_specialty'].replace(\n",
    "    {\"Orthopedics-Reconstructive\": \"Orthopedics\",\n",
    "     \"Surgeon\": \"Surgery-General\",\n",
    "     \"Surgery-Cardiovascular\": \"Surgery-Cardiovascular/Thoracic\",\n",
    "     \"Surgery-Thoracic\": \"Surgery-Cardiovascular/Thoracic\",\n",
    "     \"Pediatrics-Endocrinology\": \"Pediatrics\",\n",
    "     \"Pediatrics-CriticalCare\": \"Pediatrics\",\n",
    "     \"Pediatrics-Pulmonology\": \"Pediatrics\",\n",
    "     \"Radiologist\": \"Radiology\",\n",
    "     \"Oncology\": \"Hematology/Oncology\",\n",
    "     \"Hematology\": \"Hematology/Oncology\",\n",
    "     \"Gynecology\": \"ObstetricsandGynecology\",\n",
    "     \"Obstetrics\": \"ObstetricsandGynecology\"\n",
    "     }\n",
    ")\n",
    "df['medical_specialty'] = df['medical_specialty'].replace(\n",
    "    {spec: \"Other\" for spec in df['medical_specialty'].value_counts().index.values[15:]}\n",
    ")\n",
    "df = pd.get_dummies(df, columns=['medical_specialty'], prefix_sep=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-diving",
   "metadata": {},
   "source": [
    "### number of procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "unusual-progressive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428     6862\n",
       "414     6580\n",
       "786     4016\n",
       "410     3614\n",
       "486     3508\n",
       "        ... \n",
       "704        1\n",
       "791        1\n",
       "325        1\n",
       "911        1\n",
       "E909       1\n",
       "Name: diag_1, Length: 716, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diag_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "wired-projection",
   "metadata": {},
   "outputs": [],
   "source": [
    "### weight, payer code, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-desktop",
   "metadata": {},
   "source": [
    "# breast cancer\n",
    "https://www.openml.org/d/13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "chubby-brook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_openml_dataset(13)\n",
    "df = df.dropna()\n",
    "\n",
    "categorical_features = ['menopause', 'breast-quad', 'deg-malig']\n",
    "df_enc = pd.get_dummies(df, columns=categorical_features)\n",
    "\n",
    "X, y = df_enc.drop('recurrence-events', axis=1), df_enc['recurrence-events']\n",
    "df_clean = pd.concat([X, y], axis=1)\n",
    "df_clean.to_csv('data/breast_cancer.csv', index=False)\n",
    "\n",
    "orig_feature_count = len(df.columns) - 1\n",
    "orig_feature_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-nerve",
   "metadata": {},
   "source": [
    "# german credit\n",
    "https://www.openml.org/d/31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "developing-batch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_openml_dataset(31)\n",
    "\n",
    "categorical_features = ['checking_status', 'credit_history', 'purpose', 'savings_status', 'employment', \n",
    "                        'personal_status', 'other_parties', 'property_magnitude', 'other_payment_plans',\n",
    "                        'housing', 'job', 'own_telephone', 'foreign_worker']\n",
    "df_enc = pd.get_dummies(df, columns=categorical_features)\n",
    "\n",
    "X, y = df_enc.drop('good', axis=1), df_enc['good']\n",
    "df_clean = pd.concat([X, y], axis=1)\n",
    "df_clean.to_csv('data/credit_g.csv', index=False)\n",
    "\n",
    "orig_feature_count = len(df.columns) - 1\n",
    "orig_feature_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-badge",
   "metadata": {},
   "source": [
    "# haberman\n",
    "https://www.openml.org/d/43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "extensive-belize",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_openml_dataset(43)\n",
    "df.to_csv('data/haberman.csv', index=False)\n",
    "orig_feature_count = len(df.columns) - 1\n",
    "orig_feature_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-special",
   "metadata": {},
   "source": [
    "# heart\n",
    "https://www.openml.org/d/1574"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "trying-winner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_openml_dataset(1574)\n",
    "df = df.rename(columns={1.0:'target'})\n",
    "\n",
    "categorical_features = ['att_13']\n",
    "\n",
    "df_enc = pd.get_dummies(df, columns=categorical_features)\n",
    "\n",
    "for col in [f'att_{i}' for i in [2, 6, 7, 9, 11]]:\n",
    "    df_enc[col] = (df_enc[col] == 1.0).astype(int)\n",
    "\n",
    "X, y = df_enc.drop('target', axis=1), df_enc['target']\n",
    "df_clean = pd.concat([X, y], axis=1)\n",
    "df_clean.to_csv('data/heart.csv', index=False)\n",
    "\n",
    "orig_feature_count = len(df.columns) - 1\n",
    "orig_feature_count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
